# SPDX AI Team Meeting 2024-02-07

## Attendees
* Rhea Anthony (SAP)
* Karen Bennet (LF, IEEE, ISO)
* Ambarish Gurjar (Indiana University)
* Victor Lu (Consultant)
* Joseph Silvia (Medical Device)
* Arthit Suriyawongkul (Trinity College Dublin)
* Hasan Yasar (CMU)

## Agenda
* Welcome New Members
* Update on RC2 Punch List - SupportLevel (optional) added for AI/Dataset; Change name to standardname
* What's missing for consideration for 3.1 (Arthit, Joseph, Hasan, and Mark)
** EU AI Act may demand the ability of internet resources to forbid use for as training data. That logically will need the tags to go into robots.txt, into .well-known/, into tags in REUSE metadata, and into tags inline with datasets. Amazon has hope that SPDX can step up and step into that space.
* Round Table

## Notes
* No new members

### Introductions and agenda
* Karen kicked off the meeting by welcoming new members and setting the agenda to discuss SPDX 3.0 updates, mapping EU AI Act requirements to SPDX fields, and opportunities for collaboration on international AI regulation analysis. 

### SPDX 3.0 and RC candidate updates
* Karen provided an update on two changes recently added to SPDX 3.0 - including:
  * support levels in AI and data profiles
  * renaming the "name" field to "standard name".
* Further details on standards compliance will be discussed for SPDX 3.1.

###  EU AI Act requirements and mapping to SPDX 3.0
* Arthit shared his initial analysis mapping EU AI Act requirements (Draft Agreement 26 Jan 2024) to relevant SPDX 3.0 AI Profile fields. https://docs.google.com/spreadsheets/d/1Ybahysma1o6PFK3yc_nklYBD048rUiuYYnr5Im57cis/edit#gid=0
* Two main sets of requirements: 1) for High-risk AI _systems_ and 2) for General Purpose AI _models_
* Discussion focused on differentiating model vs. system purpose, and requirements for low-risk LLM models.
* Arthit showed a slide that summarized levels of risk in EU AI Act - to be published soon on https://adra-e.eu/
* Opportunities for further collaboration were identified. 

### Collaboration opportunities on EU AI Act and US regulations analysis
* Joseph and Arthit agreed to collaborate on their respective analyses to avoid duplication.
* A matrix comparing EU AI Act and emerging US regulations was proposed to identify alignments and deltas, supporting international harmonization efforts.
* AI Risk Management Framework https://www.nist.gov/itl/ai-risk-management-framework
* S.2892 - Algorithmic Accountability Act of 2023
  * https://www.congress.gov/bill/118th-congress/senate-bill/2892/text
  * https://www.govtrack.us/congress/bills/118/s2892
* S.3312 - Artificial Intelligence Research, Innovation, and Accountability Act of 2023
  * https://www.congress.gov/bill/118th-congress/senate-bill/3312/text
  * https://www.govtrack.us/congress/bills/118/s3312

### Harmonizing international AI regulations
* While the EU and US are not fully aligned, participation in each other's working groups is occurring.
  * For example, EU-U.S. Terminology and Taxonomy for Artificial Intelligence https://digital-strategy.ec.europa.eu/en/library/eu-us-terminology-and-taxonomy-artificial-intelligence
* A common framework and language would benefit open source development.
* Differences in how each region views and balances innovation and risk were also noted.

### Example of an S-BOM and need for use cases
* Karen requested S-BOM examples to help educate students.
* Discussion highlighted the need for practical use cases to demonstrate S-BOMs' real-world benefits and drive tooling development to automate their creation. 
