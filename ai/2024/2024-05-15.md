# SPDX AI Team Meeting 2024-05-15

## Attendees

- Venkat Ramakrishnan
- Arun Prabhakar
- Ameya Naik
- Arthit Suriyawongkul
- Karen Bennet
- Martin [NEW] from HP
- Matthew Crawford
- Victor Lu
- Dmitry Raidman

## Agenda

- Welcome New Members
- Security Strategy for AI BOMs - Venkat
- AI Bom Workshop Recap - Helen
- AI BOM Whitepaper - 
    - SPDX AI BOM examples folder created and one full AI system example posted,
      more to be posted here (instead of in the whitepaper). 
   - PR to be created (to move syntax examples per each field in from whitepaper to GitHub
- Meeting Time - consider alternating or change for Far East participants

- Events (Upcoming)
  - PyTorch Conference, 18-19 Sep 2024, San Francisco - Gopi, Any one else?
    - CFP Closes: Friday, June 7 at 11:59 pm PDT (UTC -7)
    - Suggested topics include Model Lifecycle and Management; Ethical, Social, and Regulatory Aspects
    - https://events.linuxfoundation.org/pytorch-conference/program/cfp/#overview
  -  SWSX 2025 - GenAI Agencies panel session proposal  to be submitted; - Gopi/Karen, any one else?  
    - 2025 SXSW & SXSW PanelPicker Dates  Entry Opens: 6.25- 7/21, 2024,  Community Voting: 8/6 - 18, 2024
- ISO hosting 2-day (free) workshop on AI Regulations - next Monday/Tuesday, if interested, let me know

### PR/Issues to resolve

- Approve/merge previous meeting minutes
  - 2024-05-01 https://github.com/spdx/meetings/pull/684 - Approved and ready for merge
  - 2024-04-24 https://github.com/spdx/meetings/pull/671 - Approved and ready for merge
  - 2024-04-17 https://github.com/spdx/meetings/pull/667 - Approved and ready for merge

### New documents of interest

- Taxonomy of Trustworthiness for Artificial Intelligence
  https://cltc.berkeley.edu/publication/a-taxonomy-of-trustworthiness-for-artificial-intelligence/
- Redefining Safety for Autonomous Vehicles (SafeComp 2024) - https://arxiv.org/abs/2404.16768
- Inspect, an open-source framework for large language model evaluations from the UK AI Safety Institute
  - Python library and VS Code extension https://ukgovernmentbeis.github.io/inspect_ai/
  - Press release https://www.gov.uk/government/news/ai-safety-institute-releases-new-ai-safety-evaluations-platform
- OpenAI Model Specification (draft) https://cdn.openai.com/spec/model-spec-2024-05-08.html

### Updates from LF AI groups

- Open SSF - SIG Model signing group kicked started today (https://docs.google.com/document/d/18oAsfhfKJurH-YTUFe520CAZS3lkORX1WnZmBv4Llkc/edit#heading=h.etrsjlz02gla) - Possible 3.1 Fields
- LF AI/ML -  MOF (Model Openness Framework) - evaluate model cirteria if it's Open - Possible 3.1 Field
- LF AI/ML Responsible AI WG - creating Whitepaper about GenAI  Frameworks - Input into our GenAI 3.1 dicussions

### Action Item Status

- Comments on NIST AI 600-11,  NIST AI 100-5,  NIST AI 100-4: Reducing Risks Posed by Synthetic Content
and NIST SP 800-218A due June 2
- Meeting with Hugging Face - Karen setting up - planning meeting scheduled for next week
- Meeting with EU AI Act and AI BOM requirements (Adrian) - Planned for agenda:  May 23
- Coorindation of AI BOM  (Art/Karen)
- SPDX Security group to get examples of AI speicifc vulnerabilities into example section;  
- SPDX FUSA for AI specifics cases - ISO creating new standard(s) associated with testing of AI

## Notes

- Venkat shares RSA conf video: https://www.youtube.com/watch?v=C-m2IHzBVBE
- Arun shares presentation on MLSecOps
  - Traditional ML part https://www.youtube.com/watch?v=zWJdvjJIO2w&t=233s
  - GenAI Lifecycle https://dr-arsanjani.medium.com/the-generative-ai-life-cycle-fb2271a70349
