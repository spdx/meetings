# SPDX AI Team Meeting 2024-05-08

## Attendees

- Karen Bennet
- Victor Lu
- Arthit Suriyawongkul
- Arun Prabhakar
- Ambarish Gurjar (Indiana University)
- Venkat Ramakrishnan

## Agenda

- Welcome New Members
- Full AI BOM Workshop planned for next week's agenda - Helen
- Preview of AI BOM workshop outcomes
- New documents of interest
  - NIST AI 600-11 Initial Public Draft: AI Risk Management Framework: Generative Artificial Intelligence Profile
  - NIST AI 100-5: A Plan for Global Engagement on AI Standards
  - NIST AI 100-4: Reducing Risks Posed by Synthetic Content
  - NIST SP 800-218A  Secure Software Development Practices for Generative AI and Dual-Use Foundation
  - Google: Securing the AI Software Supply Chain
- Validation tools and examples
  - GenAI discussion (Arun, Matthew and Gopi) - Gopi has requested to reschedule; other priorities have come up. 
  - EU AI requirements for AI BOMs - planned for next week's agenda (Adrian / Karen)

### Action items to resolve

- SWSX 2025 - GenAI Agencies panel session proposal  to be submitted  (Karen/Gopi)
- SPDX AI whitepaper - reviews obtained; revising; draft.
- Open PR for 3.0.1, we missed relationshipType of ValidateOn
- Move use cases to Example direction and add more! Any volunteers?  Karen, Gopi so far
- SPDX Licensing group to get missing model/dataset licenses reviewed (Art/Karen)
- SPDX Security group to get examples of AI speicifc vulnerabilities into example section
- SPDX FUSA for AI specifics cases - Any Volunteers?
- SPDX Hardware for AI specific cases;  IEEE gigital twin group to review Hardware profile
- Host meeting with SVN, GitHub, Hugginface groups on our requirements on code (AI specificly)
  hosted on their systems (Karen setting up)
- Join the AI BOM (Helen lead) work streams

## Notes 

### Preview of AI BOM workshop outcomes

- Karen summarizes to the group on AI BOM meeting she joined recently.
- One of the main points is how to encode weights into the BOM, since they can be huge
- Lightning talks on the current state of the following:
  (see GitHub for more details about presentations);
- Discussion #1 "What fields should and should not be in AI BOM";
- Other discussion topics posted at https://lnkd.in/efCaBpH5
- Summary of #1:   
  - Model side - name, version, weights (mass amount of data,  hash as much as possible),
    locality training framework  
  - Data Sets - Propose describing as a Merkel tree, hash, name, who trained it, care about org, trained framework, etc. GPU assumptions, open source vs. proprietary licensing, redaction aspects. Build explicitly into model or not. Files used, including scripts, intrinsic identifiers. Licenses key for data. Some models have some license on derivative outputs, and what can be done with them.
  - Task type - what doies model do? considering taxonomy of all possible human tasks for AI.   
- Start with set that is easiest to automate.  
- Start of more discussions and collaboration realted to AI BOM

### New documents of interest

- Documents from NIST
  https://airc.nist.gov/AI_RMF_Knowledge_Base/Technical_And_Policy_Documents 
- NIST AI 600-11 Initial Public Draft
  AI Risk Management Framework: Generative Artificial Intelligence Profile
  https://airc.nist.gov/docs/NIST.AI.600-1.GenAI-Profile.ipd.pdf
  - Karen: Best definition that I've seen for GenAI:
    "the class of AI models that emulate the structure and characteristics of
    input data in order to generate derived synthetic content.
    This can include images, videos, audio, text, and other digital content.‚Äù
- NIST AI 100-5: A Plan for Global Engagement on AI Standards
  - Any volunteers? 
- NIST AI 100-4: Reducing Risks Posed by Synthetic Content
  - Any volunteers?
- NIST SP 800-218A  Secure Software Development Practices for Generative AI and Dual-Use Foundation
  - Any volunteers
- SPDX groups to provide comments on these documents for June 2 deadline; start reading!!
  (reminder that SPDX is one of the consortium companies on the US AI Executive Order)
- Google: Securing the AI Software Supply Chain
  https://research.google/pubs/securing-the-ai-software-supply-chain/
  - Karen: If you haven't read this paper, highly recommend it. Good learnings about AI systems.

### Validation tools and examples

- Validation tools: serialization/json_ld/validation.md
- Examples: serialization/json_ld/EXAMPLES.md ; currently testing our some of our AI examples
- Need to address the overlapping with other Profiles; Like Hardware in 3.1
- More on relationship. Need examples for SPDX relationships

### Incident databases

- Discussion about demands in incident reports, like CVE in security community
- https://incidentdatabase.ai/
- AIAAIC https://www.aiaaic.org/ goes a bit further as they are not only
  collect incidents but try to come up with standardized taxonomy for AI harms and risks.
  - New version of taxonomy will be released by the end of the year
- OECD also has one. But it's more like an aggregation from other sources
  https://oecd.ai/en/catalogue/tools/ai-incident-database
