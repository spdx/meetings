SPDX AI team minutes,  May 4, 2022

Attendees:
  * Gopi Krishnan Rajbahadur
  * Karen Bennet
  * Kate Stewart
  * Derek Kruszewski

Agenda
  * AI SBOM Document - moving it further
  * AI Model Card document
  * Meta open sourcing model - use it to check fields

Notes

* Next Week:  Karen to host (Kate traveling)
* Motivating Use Case:  why we need to start to make this info transparent -  https://www.aiaaic.org/aiaaic-repository

* Comparison of Model Cards with AI SBOM field
   * https://docs.google.com/document/d/1Xq28jmhGJcsIOgib8D4fZkShsYggDAxb_vXBB7-DSBE/edit?usp=sharing
   * some fields don't have info for - additional documentation, resource for more info?   Expand scope of some of the existing SPDX fields.
   * Attribution details  -- citation?   "other info"  "standardize" ??
   * Supplier - need email of supplier to be mandatory.

* Need to discuss if Intendeded Use & intended users & out-of-scope use cases - should we extend ?
    * Karen:  Fact Sheets has concept as "Domain".   Some overlap?
    * Gopi:  Would be good to declare the indendend use as expected,   intended users & use cases as optional
    * Derek:  Getting AI authors to filling them out.   Should focus on what the minimum set are, and build up from there.   V1 of AI BOM.  Focus on what a realistic minimum is.    AI:  Derek will look at what a minimum set could be,  from work to date.    Minimize # of dynamic fields in AI SBOM.
    * Gopi:  What does AI BOM need to be,  and then chart out what needed.

* Compliance & Transparency,  start with what is needed and expand from there.
    * Decision thresholds & variation approaches - something to look at including (as optional field)
    * Training vs Testing data - make explicit as a file type would be useful.
    * Processing?   Is it equivalent to Data Collection Process?  Lineage?
    * What about Quantative analysis - like unitary results, intersectional results?   We have some aspects.
    * Derek:  Should probably be generalized as "metrics"  and let people put in what is relevant.

* Ethical Considerations:   does it belong in scope?
   * Karen:  Tradeoffs making decisions transparent.   Limitations field?    May want to add this in.   For version 1,  keeping some of these generic.   Doesn't seem to be one way to measure these things.    Gopi agrees.

* Agreement to Do this for fact sheets, and then use intersection help guide us on the minimum should consist of . .
     * Karen did some of this with Fact Sheets.
     * Dataset distribution - train, test, product?    Derek:  worth a row, but not mandatory.
     * What does it mean for production to be 10% (AI:  Ask Michael to provide more info)
     * Domain Shift - how it performs on other than training data set.  Common practice.     Derek:  nice to have, but not mandatory.
     * Fairness is measured in multiple fashions - do we want to go deep or generalize what makes sense to record in SBOM.
     * Deployment Models - agree have a placeholder, and figure out what minimum.  Makes sense  to include.
     * Next steps, take use cases, and see what actually makes sense to record.
     * May makes sense to point to other evidence.

* Meta open sourced model
   * https://www.technologyreview.com/2022/05/03/1051691/meta-ai-large-language-model-gpt3-ethics-huggingface-transparency/?utm_source=tldrnewsletter
   * https://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/
   * https://github.com/facebookresearch/metaseq/blob/main/docs/setup.md

* Comparision of AI BOM with Model cards - https://docs.google.com/document/d/1Xq28jmhGJcsIOgib8D4fZkShsYggDAxb_vXBB7-DSBE/edit?usp=sharing
   * AI Kate & Karen to do some mapping
   * AI Gopi to find other systems that we can do some mapping.
   * AI Gopi to look at comparing DataSheets as well.
   * AI Derek - put a first pass at what "minimum" is.
