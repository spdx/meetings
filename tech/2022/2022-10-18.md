#SPDX Tech Team Meeting - 18 October, 2022

## Attendees
* Adolfo Garcia Veytia
* Alexios Zavras
* Armin Tanzer
* Bob Martin
* Bryan Cowan
* David Edelsohn
* Gary ONeall
* Ivana Atansova
* Jeff Schutt
* Jennie Kauffmann
* Karsten Klein
* Kate Stewart
* Maximillian Huber
* Meret Behrens
* Nicolas Weidner
* Sebastian Crane
* Joshua Watt


## Agenda
* DocFest - Nov 11
* FOSDEM
* Testbed framework
* Build Profile - feedback request - Joshua
* Confidence indicators (decision tree for consumer confidence) -  Jeff
* 3.0 punch list items

## Notes

* DocFest - Nov 11th:  The goals is to:
1) come to agreement on how the fields should be populated for a given artifact, with a focus on the new 2.3 fields, but those that generate 2.2 are welcome.
2) identify instances where different use cases might lead to different choices for fields and structures of documents
3) assess how well the NTIA SBOM minimum elements are covered
4) create a set of reference SPDX SBOMs as part of the corpus for further tooling evaluation.
To indicate interest to participate, please fill in the following form:
https://forms.gle/xnb4nuFXomNPEp3v5
* Gary is organizing on analysis working group.
* Note:  Nov 11 is Veterans's day.   Discuss further in ACT group.

* Testbed framework  - https://github.com/TNG/spdx-testbed
  * Nico and Armin working on testbed for testing libraries.
  * Now live - looking for input.   Solver artifact - using tools/java to solve the test cases.
  * Went through demo on how to run with testcases, and how to integrate another.
  * Working to integrate go & python (as soon as they're a bit more solid) libraries.
  * Using it to figure out what is not yet working in Python tools.
  * SPDX Java library - found some bugs and submitted to the Java.
  * Next steps:  multiple tests simultaneously.
       * Adding in fuzzing, conversion.
       * Only supporting XML 2.3 so move to different versions.
       * Starting regular meeting this Thursday - sending info to SPDX-tech mailing list.
 * Gary:  Found some good bugs (embarassing to subtle).
 * Any concerns about moving this into the SPDX github repo?   Max - nothing pinned, so ok by Sebastian.     We'll look at into the SPDX repo next week.  * Decision made *

* FOSDEM
  * Alexios submitted in an SBOM Devroom proposal today
  * If you're interested in helping, let him know.
  * Software Composition has been submitted:  https://github.com/software-composition-analysis/fosdem-2023-devroom

* Build profile - feedback request
  * Current model:  https://github.com/spdx/spdx-3-model/pull/30/files
  * Github actions - does it make sense to be an identity?    How handle internal CI system?
  * Actor is for an observed factor.   Tool that ran was github actions, organization would be Github.
  * Orignatedby refers to artifact, not SPDX that describes artifact.
  * Identy - Org, Tool.    Binary created from github actions.   Someone invoked the tool with some identity.  Intermeidary.
  * Relationships indicated in diagram are just "bespoke"
  * Sebastian: final example makes most sense.
  * Build element - describes a build that happened.   It's a step in the build.   I/O that are artfacts.
  * Possible consideration of subclass approach proposed by William.
  * Build element - does it overlap with SLSA?   Yes, a lot has been cribbed from SLSA.
  * Looked into "DOCUMENT_FOR" - suggest using "DESCRIBED_BY" if you have an SPDX document for a CI you want to reference
  * More notes in SPDX BUILD Profile notes.

* Confidence Indicators (Jeff)
  * Inspected manually - discussion on how it might work with confidence.
  * Possibly consider types of an analysis.
  * Today we can created by multiple,  but we can't represent that the person who curration on top of tool.  Possibly a creator and currator role, and confidence is a factor of this.
  * How do we get to the write model, so we can add simply label.   Confidence, moderately
  * Way for one to apply to person, tool, orgs?   Would you self rank?  May want to do this.
  * Seb: Like idea give subjective rank.   Mistake to include in SPDX document itself.   While they look objective, they are actually subjective.
  * Bob: Want SPDX to convey the facts, and someone else has rubric to interpret facts in their context.
  * Confidence metric is not included in specification.
  * Gary: analogy to license conflict.  Sebastian:  More than facts.
  * Adolfo - machine generation.  Possibly the parameters of the tool be captured?
  * Maximillian - can the curator be a 3.1 topic? feels like something that could be added later.
   * **Decision**:  Add in Curator role to "Identity" as another optional property in 3.0.
     ie.  Curated by another tool, as well as another identity.

  * Gary: Decision tree:  type of tool?   Tool itself is fine.   Machine automation of category?   Defer this to rubric.
  * Adolfo:  recommend aligning with definitions being discussed in OpenSSF SBOM Everywhere, CISA SBOM Tooling, OpenChain,
  * **Decision**:  Tool type be clarified and added in 3.1 aligning with efforts from other groups.

Definitions from brainstorming:
**Auditor**: a party observing SPDX data after its creation to check for accuracy.
**Curator**: a party using output from automation to create SPDX data
An auditor may become a curator if that party is involved in amending SPDX data after finding inaccuracies.
